# To clone repo and the dependent whisper-diarization repo
git clone git@github.com:humanlab/WhisNemo.git
cd WhisNemo
conda create -n whisnemo python=3.10 -y
conda activate whisnemo
# Optional: export PIP_CACHE_DIR=/cronus_data/araghavan/.cache/pip
# git clone https://github.com/MahmoudAshraf97/whisper-diarization.git
# cd whisper-diarization
# git checkout f18edd3
# cd ..

## Edit config and code of whisper-diarization
# Add time import
# sed -i '1 a\import time' whisper-diarization/diarize.py

# Add directory and timestamp handling
# sed -i '/args = parser.parse_args()/a\
# Get the directory of the current script\
script_dir = os.path.dirname(os.path.realpath(__file__))\
timestamp = time.strftime("%Y%m%d_%H%M%S")\
output_dir = os.path.join(script_dir, f"temp_outputs_{timestamp}")' whisper-diarization/diarize.py

# Replace temp_outputs with output_dir
# sed -i 's/"{args.audio}" -o "temp_outputs"/"{args.audio}" -o "{output_dir}"/g' whisper-diarization/diarize.py
# sed -i 's/"temp_outputs",/output_dir,/g' whisper-diarization/diarize.py
# sed -i 's/temp_path = os.path.join(ROOT, "temp_outputs")/temp_path = os.path.join(ROOT, output_dir)/' whisper-diarization/diarize.py

# Update max_num_speakers to 2 in all config files
# sed -i 's/max_num_speakers: 8/max_num_speakers: 2/' whisper-diarization/nemo_msdd_configs/diar_infer_*.yaml

# Reduce infer_batch_size to 15 in all config files
# sed -i 's/infer_batch_size: 25/infer_batch_size: 15/' whisper-diarization/nemo_msdd_configs/diar_infer_*.yaml


# Packages/Libraries to be installed
pip install cython==3.0.11
pip install wget==3.2
pip install nemo_toolkit==1.20.0
pip install git+https://github.com/m-bain/whisperX.git@78dcfaab51005aa703ee21375f81ed31bc248560
pip install git+https://github.com/adefossez/demucs.git@b9ab48cad45976ba42b2ff17b229c071f0df9390
pip install git+https://github.com/oliverguhr/deepmultilingualpunctuation.git@5a0dd7f4fd56687f59405aa8eba1144393d8b74b
pip install git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git@abd458dd879305566cd4ed0c8624c95f22e3126a
pip install huggingface-hub==0.23.2
pip install ctranslate2==3.24.0
pip install PyYAML
pip install hydra-core==1.3.2
pip install youtokentome==1.0.6
pip install inflect==7.4.0
pip install webdataset==0.2.100
pip install editdistance==0.8.1
pip install jiwer==3.0.5
pip install ffmpeg==1.4
pip install pytorch-lightning==1.9.4; \
pip install ipython==8.31.0
pip install ffmpeg-python==0.2.0
pip install librosa

# Specific to Cronus for 11.8
pip install torch==2.1.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118



# If youtokentome library throws an error
# export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
# ln -sf /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /chronos_data/araghavan/.conda/envs/whisnemo/bin/../lib/libstdc++.so.6


## Sample Commands:
# For A Folder
# ./src/whisnemo_pipeline_batch_v1.0.sh "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test2" 3 1 1 10 

# For Specific File(s)
# ./src/whisnemo_specific_v1.0.sh 2 1 "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test3/P439_12202023_PM_8928.mp3" "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test3/P355_10242023_JL_6144_.mp3"


# To remove existing clone of repo and environment
# cd /cronus_data/araghavan && conda activate base && rm -rf WhisNemo && conda remove -n whisnemo --all -y && rm -rf /cronus_data/araghavan/.cache/pip 


## Ignore the rest below:
Setup Instructions:
Automatic [Recommended]:
Step 0 - Clone WhisNemo Repo
git clone https://github.com/humanlab/WhisNemo.git
cd WhisNemo

Step 1 - Setup Conda Env
cd WhisNemo/documentation/
conda env create -f whisnemo_conda_env.yaml
conda activate nemo
cd ..

Step 2 - Follow Run Instructions below

Manually [Skip if Doing it Automatic]:
Step 0 - Clone WhisNemo Repo
git clone https://github.com/humanlab/WhisNemo.git
cd WhisNemo

Step 1 - Setup Conda Env
cd WhisNemo/documentation/
conda env create -f whisnemo_conda_env.yaml
conda activate nemo
cd ..

Step 2 - Clone Whisper Diarization Repo
git clone https://github.com/MahmoudAshraf97/whisper-diarization.git
cd whisper-diarization
git checkout f18edd3

Step 3 - Make appropriate changes to files in whisper-diarization checkpoint
File 1: nemo_msdd_configs/diar_infer_telephonic.yaml
+      infer_batch_size: 15 # Batch size for MSDD inference.
+      max_num_speakers: 2 # Max number of speakers for each recording. If an oracle number of speakers is passed, this value is ignored.

File 2: nemo_msdd_configs/diar_infer_meeting.yaml
+      max_num_speakers: 2 # Max number of speakers for each recording. If an oracle number of speakers is passed, this value is ignored.
+      infer_batch_size: 15 # Batch size for MSDD inference. 
+      infer_batch_size: 15 # Batch size for MSDD inference. 
+      infer_batch_size: 15 # Batch size for MSDD inference. 

File 3 : diarize.py
-        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals "{args.audio}" -o "temp_outputs"'
+        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals "{args.audio}" -o "{output_dir}"'

-            "temp_outputs",
+            output_dir,

-temp_path = os.path.join(ROOT, "temp_outputs")
+temp_path = os.path.join(ROOT, output_dir)

File 4: nemo_msdd_configs/diar_infer_general.yaml
-      max_num_speakers: 8 # Max number of speakers for each recording. If an oracle number of speakers is passed, this value is ignored.
+      max_num_speakers: 2 # Max number of speakers for each recording. If an oracle number of speakers is passed, this value is ignored.

-      infer_batch_size: 25 # Batch size for MSDD inference. 
+      infer_batch_size: 15 # Batch size for MSDD inference. 


Run Instructions
Pre-requisites: Place audio files [mp3 and other formats] in a particular dir
Note: Ensure no two files have the same name irrespective of different extensions

If you want to run a batch of inputs with the audio files present in a folder:
./src/whisnemo_pipeline_batch_v1.0.sh "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test" 0 1 50 1

If you want to run a specific set of audio files:
./src/whisnemo_specific_v1.0.sh 0 "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test/file1" "/cronus_data/hitop/iHiTOP_transcripts/HiTOP/Audio/test/file2" 1



#Troubleshooting Common Issues

# Issue 1: WhisperX VAD Model Download Failure

**Error Message:**
```
urllib.error.HTTPError: HTTP Error 301: Moved Permanently
```

**Root Cause:** 
WhisperX's `transcribe_batched()` function tries to download a Voice Activity Detection (VAD) model from a URL that has been moved permanently:
```
https://whisperx.s3.eu-west-2.amazonaws.com/model_weights/segmentation/0b5b3216d60a2d32fc086b47ea8c67589aaeb26b7e07fcbe620d6d0b83e209ea/pytorch_model.bin
```

**Solution:**
Modify `whisper-diarization/diarize.py` to use `transcribe()` instead of `transcribe_batched()`:

1. **Change the import (around line 28):**
```python
# FROM:
from transcription_helpers import transcribe_batched

# TO:
from transcription_helpers import transcribe
import whisperx
```

2. **Change the transcription call (around lines 115-122):**
```python
# FROM:
whisper_results, language, audio_waveform = transcribe_batched(
    vocal_target,
    args.language,
    args.batch_size,
    args.model_name,
    mtypes[args.device],
    args.suppress_numerals,
    args.device,
)

# TO:
whisper_results, language = transcribe(
    vocal_target,
    args.language,
    args.model_name,
    mtypes[args.device],
    args.suppress_numerals,
    args.device,
)

# Load audio waveform separately since transcribe doesn't return it
audio_waveform = whisperx.load_audio(vocal_target)
```

**Note:** This provides identical transcription results, just potentially slightly slower than batched processing.

### Issue 2: cuDNN Version Incompatibility

**Error Message:**
```
RuntimeError: cuDNN version incompatibility: PyTorch was compiled against (8, 7, 0) but found runtime version (8, 2, 2)
```

**Root Cause:** 
System has cuDNN 8.2.2 installed, but PyTorch expects cuDNN 8.7.0. The system's older cuDNN is being loaded instead of PyTorch's bundled version.

**Solution:**
Force PyTorch to use its own bundled cuDNN libraries by setting the library path:

```bash
# For your specific environment, adjust the path accordingly:
export LD_LIBRARY_PATH="/path/to/your/conda/env/lib/python3.10/site-packages/torch/lib"

# Example for whisnemo environment:
export LD_LIBRARY_PATH="/chronos_data/dumrania/whisnemo_env/lib/python3.10/site-packages/torch/lib"
```

**Verification:**
Test that both fixes work:
```bash
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('cuDNN:', torch.backends.cudnn.version())"
```
Should show: `CUDA: True` and `cuDNN: 8700`